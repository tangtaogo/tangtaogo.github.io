---
title: "实习3: 理想汽车-自动驾驶实验室-世界模型实习生"
collection: talks
type: "实习"
permalink: /talks/2014-03-01-talk-3
venue: "2023.12–2025.11"
location: "北京"
---

• 自动驾驶场景 多模态生成:1) 参与设计 Delphi，一种基于扩散模型的长视频生成方法，引入跨视角共享噪声机 制与特征对齐模块以增强空间与时间一致性。 2) 提出首个端到端多模态场景生成框架 OmniGen，在统一 BEV 表征中融合 LiDAR 与图像，通过扩散模型生成多模态数据。 3) 提出 BEV-TSR，首个基于 BEV 空间的文本场 景检索框架，结合知识图谱与大语言模型增强语义理解，实现高精度多模态检索。
• 自动驾驶场景 多模态重建:1) 提出了首个基于神经渲染的 LiDAR 仿真生成器 LiDAR-NeRF，可端到端合成新 视角的点云数据。 2) 推出多模态统一渲染模型 AlignMiF，解决 LiDAR 与图像间的不一致问题，实现可微分的 多模态神经场建模。 3) 结合 3DGS，提出 LiDAR-GS，显著提升渲染速度与质量。 4) 推出 RoboPearls，基 于 GS 构建语义增强的动态场景重建，并结合大语言模型支持自然语言编辑，有效增强下游机器人操纵性能。
• 端到端 大模型:1) 提出基于视觉语言模型(VLM)的端到端规划方法 RDA-Drive，针对现有方法忽视因果推理 与决策间不一致的问题，引入排序对齐损失(Rank-Alignment Loss)，强化 CoT 与决策输出的一致性，实现领先的 自动驾驶规划性能。 2) 构建端到端 3D 多目标跟踪模型 S2-Track(持续领先 nuScenes 排行榜):Query 初始 化:结合 2D 目标位置与深度信息估计初始 3D 框;Query 优化:引入不确定性感知解码器，将注意力建模为高斯 分布以量化跟踪不确定性;Query 训练:通过向真实目标框添加噪声并进行去噪训练，提升匹配鲁棒性与稳定性。
